{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lifelines.utils import concordance_index\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from torchmtlr import MTLR, mtlr_neg_log_likelihood, mtlr_cif, mtlr_risk, mtlr_survival\n",
    "from torchmtlr.utils import make_time_bins, encode_survival, reset_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1129)\n",
    "torch.backends.deterministic = True\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(1129)\n",
    "device = \"cpu\"\n",
    "\n",
    "sns.set(context=\"poster\", style=\"white\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer(opt_cls, model, **kwargs):\n",
    "    \"\"\"Creates a PyTorch optimizer for MTLR training.\"\"\"\n",
    "    params_dict = dict(model.named_parameters())\n",
    "    weights = [v for k, v in params_dict.items() if \"mtlr\" not in k and \"bias\" not in k]\n",
    "    biases = [v for k, v in params_dict.items() if \"bias\" in k]\n",
    "    mtlr_weights = [v for k, v in params_dict.items() if \"mtlr_weight\" in k]\n",
    "    # Don't use weight decay on the biases and MTLR parameters, which have\n",
    "    # their own separate L2 regularization\n",
    "    optimizer = opt_cls([\n",
    "        {\"params\": weights},\n",
    "        {\"params\": biases, \"weight_decay\": 0.},\n",
    "        {\"params\": mtlr_weights, \"weight_decay\": 0.},\n",
    "    ], **kwargs)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataload function\n",
    "def make_data(path, split=\"training\"):\n",
    "    \"\"\"Load and preprocess the data.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "    except:\n",
    "        df = path\n",
    "    clinical_data = (df\n",
    "                     .query(\"split == @split\")\n",
    "                     .set_index(\"Study ID\")\n",
    "                     .drop([\"split\"], axis=1, errors=\"ignore\"))\n",
    "    \n",
    "    clinical_data = clinical_data.rename(columns={\"death\": \"event\", \"survival_time\": \"time\"})\n",
    "    # Convert time to months\n",
    "    clinical_data[\"time\"] *= 12\n",
    "        \n",
    "    # binarize T stage as T1/2 = 0, T3/4 = 1\n",
    "    clinical_data[\"T Stage\"] = clinical_data[\"T Stage\"].map(\n",
    "        lambda x: \"T1/2\" if x in [\"T1\", \"T1a\", \"T1b\", \"T2\"] else \"T3/4\")\n",
    "    \n",
    "    # use more fine-grained grouping for N stage\n",
    "    clinical_data[\"N Stage\"] = clinical_data[\"N Stage\"].map({\n",
    "        \"N0\":  \"N0\",\n",
    "        \"N1\":  \"N1\",\n",
    "        \"N2\":  \"N2\",\n",
    "        \"N2a\": \"N2\",\n",
    "        \"N2b\": \"N2\",\n",
    "        \"N2c\": \"N2\",\n",
    "        \"N3\":  \"N3\",\n",
    "        \"N3a\": \"N3\",\n",
    "        \"N3b\": \"N3\"\n",
    "    })\n",
    "    \n",
    "    clinical_data[\"age at dx\"] = scale(clinical_data[\"age at dx\"])\n",
    "    clinical_data[\"Dose\"] = scale(clinical_data[\"Dose\"])\n",
    "    \n",
    "    clinical_data[\"Stage\"] = clinical_data[\"Stage\"].map(\n",
    "        lambda x: \"I/II\" if x in [\"I\", \"II\", \"IIA\"] else \"III/IV\")\n",
    "    \n",
    "    clinical_data[\"ECOG\"] = clinical_data[\"ECOG\"].map(\n",
    "        lambda x: \">0\" if x > 0 else \"0\")\n",
    "    \n",
    "    clinical_data = pd.get_dummies(clinical_data,\n",
    "                                   columns=[\"Sex\",\n",
    "                                            \"T Stage\",\n",
    "                                            \"N Stage\",\n",
    "                                            \"Disease Site\",\n",
    "                                            \"Stage\",\n",
    "                                            \"ECOG\"],\n",
    "                                   drop_first=True)\n",
    "    clinical_data = pd.get_dummies(clinical_data, columns=[\"HPV Combined\"])\n",
    "    return clinical_data\n",
    "\n",
    "# training functions\n",
    "def train_mtlr(X, y, model, time_bins,\n",
    "               num_epochs=1000, lr=.01, weight_decay=0.,\n",
    "               C1=10., batch_size=None,\n",
    "               verbose=True, device=\"cpu\"):\n",
    "    \"\"\"Trains the MTLR model using minibatch gradient descent.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        MTLR model to train.\n",
    "    data_train : pd.DataFrame\n",
    "        The training dataset. Must contain a `time` column with the\n",
    "        event time for each sample and an `event` column containing\n",
    "        the event indicator.\n",
    "    num_epochs : int\n",
    "        Number of training epochs.\n",
    "    lr : float\n",
    "        The learning rate.\n",
    "    weight_decay : float\n",
    "        Weight decay strength for all parameters *except* the MTLR\n",
    "        weights. Only used for Deep MTLR training.\n",
    "    C1 : float\n",
    "        L2 regularization (weight decay) strenght for MTLR parameters.\n",
    "    batch_size : int\n",
    "        The batch size.\n",
    "    verbose : bool\n",
    "        Whether to display training progress.\n",
    "    device : str\n",
    "        Device name or ID to use for training.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    torch.nn.Module\n",
    "        The trained model.\n",
    "    \"\"\"\n",
    "    optimizer = make_optimizer(Adam, model, lr=lr, weight_decay=weight_decay)\n",
    "    reset_parameters(model)\n",
    "    print(X.shape, y.shape)\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    train_loader = DataLoader(TensorDataset(X, y), batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    pbar =  trange(num_epochs, disable=not verbose)\n",
    "    for i in pbar:\n",
    "        for xi, yi in train_loader:\n",
    "            xi, yi = xi.to(device), yi.to(device)\n",
    "            y_pred = model(xi)\n",
    "            loss = mtlr_neg_log_likelihood(y_pred, yi, model, C1, average=True)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        pbar.set_description(f\"[epoch {i+1: 4}/{num_epochs}]\")\n",
    "        pbar.set_postfix_str(f\"loss = {loss.item():.4f}\")\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_events(row):\n",
    "    event        = row[\"event\"]\n",
    "    cancer_death = row[\"cancer_death\"]\n",
    "\n",
    "    if event==0:\n",
    "        return 0\n",
    "    elif cancer_death==0:\n",
    "        return 1\n",
    "    elif cancer_death==1:\n",
    "        return 2\n",
    "    else:\n",
    "        raise UhOh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, X, time, other, cancer):\n",
    "    \"\"\"Returns inference of model on data X\n",
    "    params\n",
    "    ------\n",
    "    model\n",
    "        PyTorch model being tested\n",
    "    X\n",
    "        data to test moddel on\n",
    "    time, other, cancer\n",
    "        true labels for time, other, and cancer\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    pred_prob       = model(X)\n",
    "    two_year_bin    = np.digitize(2, time_bins)\n",
    "    survival_event  = mtlr_survival(pred_prob[:,:29]).detach().numpy()\n",
    "    survival_cancer = mtlr_survival(pred_prob[:,29:]).detach().numpy()\n",
    "    pred_event      = 1 - survival_event[:, two_year_bin]\n",
    "    pred_cancer     = 1 - survival_cancer[:, two_year_bin]\n",
    "    \n",
    "    roc_auc_event   = roc_auc_score(other, pred_event)\n",
    "    roc_auc_cancer  = roc_auc_score(cancer, pred_cancer)\n",
    "\n",
    "    pred_risk = mtlr_risk(pred_prob, 2).detach().numpy()\n",
    "        \n",
    "    ci_event  = concordance_index(time, -pred_risk[:, 0], event_observed=other)\n",
    "    ci_cancer = concordance_index(time, -pred_risk[:, 1], event_observed=cancer)\n",
    "    \n",
    "    return roc_auc_event, roc_auc_cancer, ci_event, ci_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load/process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df        = make_data(\"/cluster/projects/radiomics/RADCURE-challenge/data/training/clinical.csv\")\n",
    "time_bins = make_time_bins(df[\"time\"], event=df[\"event\"])\n",
    "multi_events = df.apply(lambda x: multiple_events(x), axis=1)\n",
    "\n",
    "y = encode_survival(df[\"time\"], multi_events, time_bins)\n",
    "X = torch.tensor(df.drop([\"time\", \"event\", \"target_binary\", \"cancer_death\"], axis=1).values, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_indices = range(len(df))\n",
    "full_targets = df[\"target_binary\"]\n",
    "train_indices, val_indices = train_test_split(full_indices, test_size=0.25, stratify=full_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = X[train_indices], X[val_indices]\n",
    "y_train, y_val = y[train_indices], y[val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = df.iloc[val_indices]\n",
    "\n",
    "true_time   = val_data[\"time\"]\n",
    "true_event  = val_data[\"event\"]\n",
    "true_cancer = val_data[\"cancer_death\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit MTLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch    8/500]:   1%|          | 4/500 [00:00<00:13, 37.96it/s, loss = 132.0287]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1351, 20]) torch.Size([1351, 58])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch  500/500]: 100%|██████████| 500/500 [00:12<00:00, 40.34it/s, loss = 1.9435] \n"
     ]
    }
   ],
   "source": [
    "# fit MTLR model \n",
    "mtlr = MTLR(in_features=20, num_time_bins=29, num_events=2)            \n",
    "mtlr = train_mtlr(X_train, y_train, mtlr, time_bins, num_epochs=500, \n",
    "                  lr=.0002, batch_size=128, verbose=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7295530934893564,\n",
       " 0.7305797650625236,\n",
       " 0.6536868196630382,\n",
       " 0.7182150264681298)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(mtlr, X_val, true_time, true_event, true_cancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"/cluster/projects/radiomics/RADCURE-challenge/clinical_cancer_death.csv\")\n",
    "df2 = pd.read_csv(\"/cluster/projects/radiomics/RADCURE-challenge/data/clinical_test.csv\")\n",
    "dff = make_data(pd.merge(df1, df2[[\"Study ID\", \"ECOG\"]], how='inner', on='Study ID'), split=\"test\").drop(\"EGFRI\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.tensor(dff.drop([\"time\", \"event\", \"target_binary\", \"cancer_death\"], axis=1).values, dtype=torch.float)\n",
    "\n",
    "true_time_test   = dff[\"time\"]\n",
    "true_event_test  = dff[\"event\"]\n",
    "true_cancer_test = dff[\"cancer_death\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6467351430667645,\n",
       " 0.7082955095618493,\n",
       " 0.6211315633027111,\n",
       " 0.7054066472660439)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(mtlr, X_test, dff[\"time\"], dff[\"event\"], dff[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTLR + hiddenlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch    6/500]:   1%|          | 3/500 [00:00<00:17, 28.93it/s, loss = 354.2757]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1351, 20]) torch.Size([1351, 58])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch  500/500]: 100%|██████████| 500/500 [00:15<00:00, 32.96it/s, loss = 1.6268] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.747904477364206, 0.746321207528104, 0.7070217707827775, 0.7516794105810606)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlr1 = nn.Sequential(\n",
    "    nn.Linear(20, 532),\n",
    "    nn.ReLU(),\n",
    "    MTLR(532, 29, num_events=2)\n",
    ")\n",
    "mtlr1 = train_mtlr(X_train, y_train, mtlr1, time_bins, num_epochs=500, \n",
    "                   lr=.0002, batch_size=128, verbose=True, device=device)\n",
    "\n",
    "validate(mtlr1, X_val, true_time, true_event, true_cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch    4/500]:   0%|          | 2/500 [00:00<00:25, 19.67it/s, loss = 401.8694]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1351, 20]) torch.Size([1351, 58])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch  500/500]: 100%|██████████| 500/500 [00:38<00:00, 13.15it/s, loss = 2.1577] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7480185899829868, 0.752273588480485, 0.7160351521874784, 0.737098721480977)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlr2 = nn.Sequential(\n",
    "    nn.Linear(20, 532),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(532, 532),\n",
    "    nn.ReLU(),\n",
    "    MTLR(532, 29, num_events=2)\n",
    ")\n",
    "mtlr2 = train_mtlr(X_train, y_train, mtlr2, time_bins, num_epochs=500, \n",
    "                   lr=.0002, batch_size=128, verbose=True, device=device)\n",
    "\n",
    "validate(mtlr2, X_val, true_time, true_event, true_cancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test deep MTLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7507948153582782,\n",
       " 0.7715822440087146,\n",
       " 0.7164642011867506,\n",
       " 0.7748812988206464)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(mtlr1, X_test, dff[\"time\"], dff[\"event\"], dff[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7502358243370716,\n",
       " 0.7674670176712659,\n",
       " 0.7297842985496518,\n",
       " 0.7476183182723235)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(mtlr2, X_test, dff[\"time\"], dff[\"event\"], dff[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fuck me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch    6/1000]:   0%|          | 3/1000 [00:00<00:33, 29.65it/s, loss = 430.5145]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1351, 20]) torch.Size([1351, 58])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch  1000/1000]: 100%|██████████| 1000/1000 [00:33<00:00, 30.16it/s, loss = 1.8031]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.761211845951391, 0.7718318809005082, 0.7206873731085461, 0.776948996783581)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlr_test = nn.Sequential(\n",
    "    nn.Linear(20, 532),\n",
    "    nn.ReLU(),\n",
    "    MTLR(532, 29, num_events=2)\n",
    ")\n",
    "mtlr_test = train_mtlr(X_train, y_train, mtlr_test, time_bins, num_epochs=1000, \n",
    "                  lr=.0001, batch_size=128, verbose=True, device=device)\n",
    "\n",
    "validate(mtlr_test, X_test, dff[\"time\"], dff[\"event\"], dff[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch    3/1000]:   0%|          | 2/1000 [00:00<01:05, 15.33it/s, loss = 464.4609]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1351, 20]) torch.Size([1351, 58])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch  1000/1000]: 100%|██████████| 1000/1000 [00:30<00:00, 32.27it/s, loss = 1.7256]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7649035158206104,\n",
       " 0.7766279351246671,\n",
       " 0.7271539298493567,\n",
       " 0.7790779598713432)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlr_test = nn.Sequential(\n",
    "    nn.Linear(20, 532),\n",
    "    nn.ReLU(),\n",
    "    MTLR(532, 29, num_events=2)\n",
    ")\n",
    "mtlr_test = train_mtlr(X_train, y_train, mtlr_test, time_bins, num_epochs=1000, \n",
    "                  lr=.0001, batch_size=128, verbose=True, device=device)\n",
    "\n",
    "validate(mtlr_test, X_test, dff[\"time\"], dff[\"event\"], dff[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch    6/1000]:   0%|          | 4/1000 [00:00<00:32, 30.88it/s, loss = 422.3957]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1351, 20]) torch.Size([1351, 58])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch  1000/1000]: 100%|██████████| 1000/1000 [00:31<00:00, 31.29it/s, loss = 2.3196]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7649268071131609,\n",
       " 0.7703038005325586,\n",
       " 0.7253087458357169,\n",
       " 0.7750497779139225)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlr_test = nn.Sequential(\n",
    "    nn.Linear(20, 532),\n",
    "    nn.ReLU(),\n",
    "    MTLR(532, 29, num_events=2)\n",
    ")\n",
    "mtlr_test = train_mtlr(X_train, y_train, mtlr_test, time_bins, num_epochs=1000, \n",
    "                  lr=.0001, batch_size=128, verbose=True, device=device)\n",
    "\n",
    "validate(mtlr_test, X_test, dff[\"time\"], dff[\"event\"], dff[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch    4/1000]:   0%|          | 2/1000 [00:00<00:52, 19.07it/s, loss = 453.1712]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1351, 20]) torch.Size([1351, 58])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch  1000/1000]: 100%|██████████| 1000/1000 [01:01<00:00, 16.14it/s, loss = 1.6403]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7330934330200654,\n",
       " 0.7645848462841927,\n",
       " 0.7245628203833945,\n",
       " 0.7376474192066166)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlr_test = nn.Sequential(\n",
    "    nn.Linear(20, 532),\n",
    "    nn.ReLU(),\n",
    "    #nn.Dropout(0.4),\n",
    "    nn.Linear(532, 532),\n",
    "    nn.ReLU(),\n",
    "    #nn.Dropout(0.4),\n",
    "    MTLR(532, 29, num_events=2)\n",
    ")\n",
    "mtlr_test = train_mtlr(X_train, y_train, mtlr_test, time_bins, num_epochs=1000, \n",
    "                  lr=.0001, batch_size=128, verbose=True, device=device)\n",
    "\n",
    "validate(mtlr_test, X_test, dff[\"time\"], dff[\"event\"], dff[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch    4/1000]:   0%|          | 2/1000 [00:00<00:50, 19.87it/s, loss = 448.1322]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1351, 20]) torch.Size([1351, 58])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch  1000/1000]: 100%|██████████| 1000/1000 [01:04<00:00, 15.58it/s, loss = 1.8524]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7412453854126634, 0.771536855482934, 0.7329867303787956, 0.7451064481543881)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlr_test = nn.Sequential(\n",
    "    nn.Linear(20, 532),\n",
    "    nn.ReLU(),\n",
    "    #nn.Dropout(0.4),\n",
    "    nn.Linear(532, 532),\n",
    "    nn.ReLU(),\n",
    "    #nn.Dropout(0.4),\n",
    "    MTLR(532, 29, num_events=2)\n",
    ")\n",
    "mtlr_test = train_mtlr(X_train, y_train, mtlr_test, time_bins, num_epochs=1000, \n",
    "                  lr=.0001, batch_size=128, verbose=True, device=device)\n",
    "\n",
    "validate(mtlr_test, X_test, dff[\"time\"], dff[\"event\"], dff[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
