{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print (\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines.utils import concordance_index\n",
    "from torchmtlr import MTLR, mtlr_neg_log_likelihood, mtlr_cif, mtlr_risk, mtlr_survival\n",
    "from torchmtlr.utils import make_time_bins, encode_survival, reset_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ezpz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def make_optimizer(opt_cls, model, **kwargs):\n",
    "    \"\"\"Creates a PyTorch optimizer for MTLR training.\"\"\"\n",
    "    params_dict = dict(model.named_parameters())\n",
    "    weights = [v for k, v in params_dict.items() if \"mtlr\" not in k and \"bias\" not in k]\n",
    "    biases = [v for k, v in params_dict.items() if \"bias\" in k]\n",
    "    mtlr_weights = [v for k, v in params_dict.items() if \"mtlr_weight\" in k]\n",
    "    # Don't use weight decay on the biases and MTLR parameters, which have\n",
    "    # their own separate L2 regularization\n",
    "    optimizer = opt_cls([\n",
    "        {\"params\": weights},\n",
    "        {\"params\": biases, \"weight_decay\": 0.},\n",
    "        {\"params\": mtlr_weights, \"weight_decay\": 0.},\n",
    "    ], **kwargs)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def make_data(path, split=\"training\"):\n",
    "    \"\"\"Load and preprocess the data.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "    except:\n",
    "        df = path\n",
    "\n",
    "    clinical_data = (df\n",
    "                     .query(\"split == @split\")\n",
    "                     .set_index(\"Study ID\")\n",
    "                     .drop([\"split\"], axis=1, errors=\"ignore\"))\n",
    "    # if split == \"training\":\n",
    "    clinical_data = clinical_data.rename(columns={\"death\": \"event\", \"survival_time\": \"time\"})\n",
    "    # Convert time to months\n",
    "    clinical_data[\"time\"] *= 12\n",
    "\n",
    "    clinical_data[\"age at dx\"] = scale(clinical_data[\"age at dx\"])\n",
    "    clinical_data[\"Dose\"] = scale(clinical_data[\"Dose\"])\n",
    "\n",
    "    # binarize T stage as T1/2 = 0, T3/4 = 1\n",
    "    clinical_data[\"T Stage\"] = clinical_data[\"T Stage\"].map(\n",
    "        lambda x: \"T1/2\" if x in [\"T1\", \"T1a\", \"T1b\", \"T2\"] else \"T3/4\", na_action=\"ignore\")\n",
    "\n",
    "    # use more fine-grained grouping for N stage\n",
    "    clinical_data[\"N Stage\"] = clinical_data[\"N Stage\"].str.slice(0, 2)\n",
    "\n",
    "    clinical_data[\"Stage\"] = clinical_data[\"Stage\"].map(\n",
    "        lambda x: \"I/II\" if x in [\"I\", \"II\", \"IIA\"] else \"III/IV\", na_action=\"ignore\")\n",
    "\n",
    "    clinical_data[\"ECOG\"] = clinical_data[\"ECOG\"].map(\n",
    "        lambda x: \">0\" if x > 0 else \"0\", na_action=\"ignore\")\n",
    "\n",
    "    clinical_data = pd.get_dummies(clinical_data,\n",
    "                                   columns=[\"Sex\",\n",
    "                                            \"N Stage\",\n",
    "                                            \"Disease Site\"],\n",
    "                                   drop_first=True)\n",
    "    clinical_data = pd.get_dummies(clinical_data,\n",
    "                                   columns=[\"HPV Combined\",\n",
    "                                            \"T Stage\",\n",
    "                                            \"Stage\",\n",
    "                                            \"ECOG\"])\n",
    "\n",
    "    return clinical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def multiple_events(row):\n",
    "    event        = row[\"event\"]\n",
    "    cancer_death = row[\"cancer_death\"]\n",
    "\n",
    "    if event==0:\n",
    "        return 0\n",
    "    elif cancer_death==0:\n",
    "        return 1\n",
    "    elif cancer_death==1:\n",
    "        return 2\n",
    "    else:\n",
    "        raise UhOh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train_mtlr(x, y, model, time_bins,\n",
    "               num_epochs=1000, lr=.01, weight_decay=0.,\n",
    "               C1=1., batch_size=None,\n",
    "               verbose=True, device=\"cpu\"):\n",
    "    \"\"\"Trains the MTLR model using minibatch gradient descent.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        MTLR model to train.\n",
    "    data_train : pd.DataFrame\n",
    "        The training dataset. Must contain a `time` column with the\n",
    "        event time for each sample and an `event` column containing\n",
    "        the event indicator.\n",
    "    num_epochs : int\n",
    "        Number of training epochs.\n",
    "    lr : float\n",
    "        The learning rate.\n",
    "    weight_decay : float\n",
    "        Weight decay strength for all parameters *except* the MTLR\n",
    "        weights. Only used for Deep MTLR training.\n",
    "    C1 : float\n",
    "        L2 regularization (weight decay) strenght for MTLR parameters.\n",
    "    batch_size : int\n",
    "        The batch size.\n",
    "    verbose : bool\n",
    "        Whether to display training progress.\n",
    "    device : str\n",
    "        Device name or ID to use for training.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    torch.nn.Module\n",
    "        The trained model.\n",
    "    \"\"\"\n",
    "    optimizer = make_optimizer(Adam, model, lr=lr, weight_decay=weight_decay)\n",
    "    reset_parameters(model)\n",
    "    print(x.shape, y.shape)\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    train_loader = DataLoader(TensorDataset(x, y), batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    pbar =  trange(num_epochs, disable=not verbose)\n",
    "    for i in pbar:\n",
    "        for xi, yi in train_loader:\n",
    "            xi, yi = xi.to(device), yi.to(device)\n",
    "            y_pred = model(xi)\n",
    "            loss = mtlr_neg_log_likelihood(y_pred, yi, model, C1, average=True)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        pbar.set_description(f\"[epoch {i+1: 4}/{num_epochs}]\")\n",
    "        pbar.set_postfix_str(f\"loss = {loss.item():.4f}\")\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def validate(model, X, time, other, cancer):\n",
    "    \"\"\"Returns inference of model on data X\n",
    "    params\n",
    "    ------\n",
    "    model\n",
    "        PyTorch model being tested\n",
    "    X\n",
    "        data to test on\n",
    "    time, other, cancer\n",
    "        true labels for time, other, and cancer\n",
    "    \"\"\"\n",
    "    pred_prob       = model(X)\n",
    "    two_year_bin    = np.digitize(2, time_bins)\n",
    "    survival_event  = mtlr_survival(pred_prob[:,:29]).detach().numpy()\n",
    "    survival_cancer = mtlr_survival(pred_prob[:,29:]).detach().numpy()\n",
    "    pred_event      = 1 - survival_event[:, two_year_bin]\n",
    "    pred_cancer     = 1 - survival_cancer[:, two_year_bin]\n",
    "    \n",
    "    roc_auc_event   = roc_auc_score(other, pred_event)\n",
    "    roc_auc_cancer  = roc_auc_score(cancer, pred_cancer)\n",
    "\n",
    "    pred_risk = mtlr_risk(pred_prob, 2).detach().numpy()\n",
    "        \n",
    "    ci_event  = concordance_index(time, -pred_risk[:, 0], event_observed=other)\n",
    "    ci_cancer = concordance_index(time, -pred_risk[:, 1], event_observed=cancer)\n",
    "    \n",
    "    return roc_auc_cancer, roc_auc_event, ci_cancer, ci_event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load/process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"/cluster/projects/radiomics/RADCURE-challenge/clinical_cancer_death.csv\")\n",
    "df2 = pd.read_csv(\"/cluster/projects/radiomics/RADCURE-challenge/data/clinical_test.csv\")\n",
    "df3 = pd.read_csv(\"/cluster/projects/radiomics/RADCURE-challenge/data/clinical.csv\")\n",
    "ddf = pd.merge(df1, pd.concat([df2[[\"Study ID\", \"ECOG\"]], df3[[\"Study ID\", \"ECOG\"]]]), \n",
    "              how='outer', on='Study ID').drop(\"EGFRI\", axis=1)\n",
    "\n",
    "df  = make_data(ddf, split=\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df        = make_data(\"/cluster/projects/radiomics/RADCURE-challenge/data/training/clinical.csv\")\n",
    "time_bins = make_time_bins(df[\"time\"], event=df[\"event\"])\n",
    "multi_events = df.apply(lambda x: multiple_events(x), axis=1)\n",
    "\n",
    "y = encode_survival(df[\"time\"], multi_events, time_bins)\n",
    "X = torch.tensor(df.drop([\"time\", \"event\", \"target_binary\", \"cancer_death\"], axis=1).values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_indices = range(len(df))\n",
    "full_targets = df[\"target_binary\"]\n",
    "val_size = floor(.1 / .7 * len(full_indices))\n",
    "\n",
    "train_indices, val_indices = train_test_split(full_indices, test_size=val_size, stratify=full_targets, random_state=1129)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = X[train_indices], X[val_indices]\n",
    "y_train, y_val = y[train_indices], y[val_indices]\n",
    "\n",
    "df_val = df.iloc[val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1545, 24]) torch.Size([257, 24])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = make_data(ddf, split=\"test\")\n",
    "df_test.insert(11, 'N Stage_NX', np.zeros(df_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.tensor(df_test.drop([\"time\", \"event\", \"target_binary\", \"cancer_death\"], axis=1).values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1129"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(1129)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C1=1. (late nov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit mellow MTLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch    3/350]:   0%|          | 1/350 [00:00<00:37,  9.19it/s, loss = 14.7189]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1545, 24]) torch.Size([1545, 58])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch  350/350]: 100%|██████████| 350/350 [00:12<00:00, 27.19it/s, loss = 1.6799]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7783771106941839, 0.758510906569159, 0.764453477868112, 0.6833411130128105)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit MTLR model \n",
    "mtlr = MTLR(in_features=24, num_time_bins=29, num_events=2)            \n",
    "mtlr = train_mtlr(X_train, y_train, mtlr, time_bins, num_epochs=350, \n",
    "                  lr=1e-3, batch_size=128, verbose=True, device=device, C1=1.)\n",
    "\n",
    "validate(mtlr, X_val, df_val[\"time\"], df_val[\"event\"], df_val[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7442810457516339,\n",
       " 0.7232062793324715,\n",
       " 0.7470975647112881,\n",
       " 0.6786743839104441)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST MODEL ##\n",
    "validate(mtlr, X_test, df_test[\"time\"], df_test[\"event\"], df_test[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-MTLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch    2/350]:   1%|          | 2/350 [00:00<00:32, 10.82it/s, loss = 31.4964]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1545, 24]) torch.Size([1545, 58])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch  350/350]: 100%|██████████| 350/350 [00:44<00:00,  7.93it/s, loss = 1.8870]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7621013133208255,\n",
       " 0.7870066826377506,\n",
       " 0.7438572719060524,\n",
       " 0.7153933924588973)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlr1 = nn.Sequential(\n",
    "    nn.Linear(24, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.2),\n",
    "    \n",
    "    MTLR(512, 29, num_events=2)\n",
    ")\n",
    "\n",
    "mtlr1 = train_mtlr(X_train, y_train, mtlr1, time_bins, num_epochs=350, \n",
    "                   lr=1e-3, batch_size=128, verbose=True, device=device, C1=1.)\n",
    "\n",
    "validate(mtlr1, X_val, df_val[\"time\"], df_val[\"event\"], df_val[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7676939603001695,\n",
       " 0.7551910468271437,\n",
       " 0.7558891101240619,\n",
       " 0.7256116027862839)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST MODEL ##\n",
    "validate(mtlr1, X_test, df_test[\"time\"], df_test[\"event\"], df_test[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch    1/350]:   0%|          | 1/350 [00:00<00:58,  5.94it/s, loss = 42.5312]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1545, 24]) torch.Size([1545, 58])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch  350/350]: 100%|██████████| 350/350 [01:05<00:00,  5.33it/s, loss = 3.3332]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7000938086303939, 0.7291640398436515, 0.6863143631436315, 0.675509569005757)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlr2 = nn.Sequential(\n",
    "    nn.Linear(24, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.2),\n",
    "    \n",
    "    nn.Linear(512, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.2),\n",
    "    \n",
    "    MTLR(512, 29, num_events=2)\n",
    ")\n",
    "\n",
    "mtlr2 = train_mtlr(X_train, y_train, mtlr2, time_bins, num_epochs=350, \n",
    "                   lr=1e-3, batch_size=128, verbose=True, device=device, C1=1.)\n",
    "\n",
    "validate(mtlr2, X_val, df_val[\"time\"], df_val[\"event\"], df_val[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7548338779956427,\n",
       " 0.6825163912471323,\n",
       " 0.7146883136774391,\n",
       " 0.6573005350472794)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST MODEL ##\n",
    "validate(mtlr2, X_test, df_test[\"time\"], df_test[\"event\"], df_test[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/450 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1545, 24]) torch.Size([1545, 58])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch  450/450]: 100%|██████████| 450/450 [02:02<00:00,  3.67it/s, loss = 1.4988]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6676829268292683, 0.689509519606607, 0.6225383920505871, 0.6697526061926249)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlr3 = nn.Sequential(\n",
    "    nn.Linear(24, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.2),\n",
    "    \n",
    "    nn.Linear(512, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.2),\n",
    "    \n",
    "    nn.Linear(512, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.2),\n",
    "    \n",
    "    MTLR(512, 29, num_events=2)\n",
    ")\n",
    "\n",
    "mtlr3 = train_mtlr(X_train, y_train, mtlr3, time_bins, num_epochs=450, \n",
    "                   lr=1e-3, batch_size=128, verbose=True, device=device, C1=1.)\n",
    "\n",
    "validate(mtlr3, X_val, df_val[\"time\"], df_val[\"event\"], df_val[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.723160251755023, 0.6591552248192013, 0.6943176596722316, 0.6495384235734877)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST MODEL ##\n",
    "validate(mtlr3, X_test, df_test[\"time\"], df_test[\"event\"], df_test[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1545, 24]) torch.Size([1545, 58])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch  350/350]: 100%|██████████| 350/350 [01:34<00:00,  3.72it/s, loss = 2.1508]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6674953095684804,\n",
       " 0.7144118017904426,\n",
       " 0.6264227642276423,\n",
       " 0.6774804211399824)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlr2 = nn.Sequential(\n",
    "    nn.Linear(24, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    #nn.Dropout(0.333),\n",
    "    \n",
    "    nn.Linear(512, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    #nn.Dropout(0.333),\n",
    "    \n",
    "    MTLR(512, 29, num_events=2)\n",
    ")\n",
    "\n",
    "mtlr2 = train_mtlr(X_train, y_train, mtlr2, time_bins, num_epochs=350, \n",
    "                   lr=1e-4, batch_size=128, verbose=True, device=device)\n",
    "\n",
    "validate(mtlr2, X_val, df_val[\"time\"], df_val[\"event\"], df_val[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7535781287823772, 0.6954197673199874, 0.7233420125593506, 0.679403483976624)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST MODEL ##\n",
    "validate(mtlr2, X_test, dff[\"time\"], dff[\"event\"], dff[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# with C1=10 (late oct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## fit mellow MTLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch    3/500]:   0%|          | 2/500 [00:00<00:28, 17.40it/s, loss = 168.5258]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1545, 24]) torch.Size([1545, 58])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch  127/500]:  25%|██▌       | 127/500 [00:07<00:21, 17.04it/s, loss = 35.5453]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-406f1604b94f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fit MTLR model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmtlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMTLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_time_bins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m29\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_events\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m mtlr = train_mtlr(X_train, y_train, mtlr, time_bins, num_epochs=500, \n\u001b[0m\u001b[1;32m      4\u001b[0m                   lr=1e-4, batch_size=128, verbose=True, device=device, C1=10.)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-1eb00c58c2b3>\u001b[0m in \u001b[0;36mtrain_mtlr\u001b[0;34m(x, y, model, time_bins, num_epochs, lr, weight_decay, C1, batch_size, verbose, device)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mxi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmtlr_neg_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aaai-survival/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aaai-survival/lib/python3.8/site-packages/torchmtlr/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mtime\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmtlr_weight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmtlr_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;31m# (n (event time)) -> (n event time)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_events\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit MTLR model \n",
    "mtlr = MTLR(in_features=24, num_time_bins=29, num_events=2)            \n",
    "mtlr = train_mtlr(X_train, y_train, mtlr, time_bins, num_epochs=500, \n",
    "                  lr=1e-4, batch_size=128, verbose=True, device=device, C1=10.)\n",
    "\n",
    "validate(mtlr, X_val, df_val[\"time\"], df_val[\"event\"], df_val[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## TEST MODEL ##\n",
    "validate(mtlr, X_test, dff[\"time\"], dff[\"event\"], dff[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## MTLR + hiddenlayers\n",
    "fc > BN > ReLU > Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch    1/500]:   0%|          | 1/500 [00:00<01:05,  7.59it/s, loss = 486.6324]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1545, 24]) torch.Size([1545, 58])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch  500/500]: 100%|██████████| 500/500 [00:49<00:00, 10.03it/s, loss = 1.7968] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7807223264540337,\n",
       " 0.7835392762577228,\n",
       " 0.7788166214995483,\n",
       " 0.7217727296302059)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlr1 = nn.Sequential(\n",
    "    nn.Linear(24, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.333),\n",
    "    \n",
    "    MTLR(512, 29, num_events=2)\n",
    ")\n",
    "\n",
    "mtlr1 = train_mtlr(X_train, y_train, mtlr1, time_bins, num_epochs=500, \n",
    "                   lr=1e-4, batch_size=128, verbose=True, device=device, C1=10.)\n",
    "\n",
    "validate(mtlr1, X_val, df_val[\"time\"], df_val[\"event\"], df_val[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7760000605180343, 0.7641989542209645, 0.7772093735640986, 0.736060167580846)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST MODEL ##\n",
    "validate(mtlr1, X_test, dff[\"time\"], dff[\"event\"], dff[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch    1/500]:   0%|          | 1/500 [00:00<01:32,  5.41it/s, loss = 492.0235]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1545, 24]) torch.Size([1545, 58])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch  500/500]: 100%|██████████| 500/500 [01:19<00:00,  6.30it/s, loss = 1.0344] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7670262664165103,\n",
       " 0.7946349766738116,\n",
       " 0.7597560975609756,\n",
       " 0.7412219283232198)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlr2 = nn.Sequential(\n",
    "    nn.Linear(24, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.333),\n",
    "    \n",
    "    nn.Linear(512, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.333),\n",
    "    \n",
    "    MTLR(512, 29, num_events=2)\n",
    ")\n",
    "\n",
    "mtlr2 = train_mtlr(X_train, y_train, mtlr2, time_bins, num_epochs=500, \n",
    "                   lr=1e-4, batch_size=128, verbose=True, device=device, C1=10.)\n",
    "\n",
    "validate(mtlr2, X_val, df_val[\"time\"], df_val[\"event\"], df_val[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7637678528201405,\n",
       " 0.7779815765875928,\n",
       " 0.7631030785725226,\n",
       " 0.7471705308970175)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST MODEL ##\n",
    "validate(mtlr2, X_test, dff[\"time\"], dff[\"event\"], dff[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1545, 24]) torch.Size([1545, 58])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch  500/500]: 100%|██████████| 500/500 [01:52<00:00,  4.45it/s, loss = 1.4053] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7374765478424015,\n",
       " 0.7832871012482663,\n",
       " 0.7228093947606142,\n",
       " 0.7241584980032156)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlr3 = nn.Sequential(\n",
    "    nn.Linear(24, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.333),\n",
    "    \n",
    "    nn.Linear(512, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.333),\n",
    "    \n",
    "    nn.Linear(512, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.333),\n",
    "    \n",
    "    MTLR(512, 29, num_events=2)\n",
    ")\n",
    "\n",
    "mtlr3 = train_mtlr(X_train, y_train, mtlr3, time_bins, num_epochs=500, \n",
    "                   lr=1e-4, batch_size=128, verbose=True, device=device, C1=10.)\n",
    "\n",
    "validate(mtlr3, X_val, df_val[\"time\"], df_val[\"event\"], df_val[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7597887920600338,\n",
       " 0.7682691075941258,\n",
       " 0.7534997702557819,\n",
       " 0.7387410124395688)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST MODEL ##\n",
    "validate(mtlr3, X_test, dff[\"time\"], dff[\"event\"], dff[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# PReLU test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch    2/500]:   0%|          | 2/500 [00:00<00:38, 13.10it/s, loss = 52.7896]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1545, 24]) torch.Size([1545, 58])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch  500/500]: 100%|██████████| 500/500 [00:46<00:00, 10.73it/s, loss = 2.9112]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7800656660412758, 0.783097969991174, 0.7724932249322494, 0.7295005445775634)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlr1 = nn.Sequential(\n",
    "    nn.Linear(24, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.PReLU(),\n",
    "    nn.Dropout(0.333),\n",
    "    \n",
    "    MTLR(512, 29, num_events=2)\n",
    ")\n",
    "\n",
    "mtlr1 = train_mtlr(X_train, y_train, mtlr1, time_bins, num_epochs=500, \n",
    "                   lr=.0001, batch_size=128, verbose=True, device=device)\n",
    "\n",
    "validate(mtlr1, X_val, df_val[\"time\"], df_val[\"event\"], df_val[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7817568385378842,\n",
       " 0.7744878827050508,\n",
       " 0.7718027262980548,\n",
       " 0.7380287377595316)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(mtlr1, X_test, dff[\"time\"], dff[\"event\"], dff[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch    1/500]:   0%|          | 1/500 [00:00<00:53,  9.36it/s, loss = 496.2234]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1545, 24]) torch.Size([1545, 58])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch  500/500]: 100%|██████████| 500/500 [00:47<00:00, 10.56it/s, loss = 2.0669] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7844746716697937, 0.7841697137813644, 0.783423667570009, 0.7311083450028526)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlr1 = nn.Sequential(\n",
    "    nn.Linear(24, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.PReLU(),\n",
    "    nn.Dropout(0.333),\n",
    "    \n",
    "    MTLR(512, 29, num_events=2)\n",
    ")\n",
    "\n",
    "mtlr1 = train_mtlr(X_train, y_train, mtlr1, time_bins, num_epochs=500, \n",
    "                   lr=.0001, batch_size=128, verbose=True, device=device, C1=10.)\n",
    "\n",
    "validate(mtlr1, X_val, df_val[\"time\"], df_val[\"event\"], df_val[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7778836843379326,\n",
       " 0.7745985163446643,\n",
       " 0.7824169091744524,\n",
       " 0.7447869345268141)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(mtlr1, X_test, dff[\"time\"], dff[\"event\"], dff[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It's cool and works well >> but i'll pass for the sake of keeping this study simpler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# some other trial runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch    6/1000]:   0%|          | 3/1000 [00:00<00:33, 29.65it/s, loss = 430.5145]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1351, 20]) torch.Size([1351, 58])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch  1000/1000]: 100%|██████████| 1000/1000 [00:33<00:00, 30.16it/s, loss = 1.8031]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.761211845951391, 0.7718318809005082, 0.7206873731085461, 0.776948996783581)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlr_test = nn.Sequential(\n",
    "    nn.Linear(20, 532),\n",
    "    nn.ReLU(),\n",
    "    MTLR(532, 29, num_events=2)\n",
    ")\n",
    "mtlr_test = train_mtlr(X_train, y_train, mtlr_test, time_bins, num_epochs=1000, \n",
    "                  lr=.0001, batch_size=128, verbose=True, device=device)\n",
    "\n",
    "validate(mtlr_test, X_test, dff[\"time\"], dff[\"event\"], dff[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch    3/1000]:   0%|          | 2/1000 [00:00<01:05, 15.33it/s, loss = 464.4609]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1351, 20]) torch.Size([1351, 58])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch  1000/1000]: 100%|██████████| 1000/1000 [00:30<00:00, 32.27it/s, loss = 1.7256]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7649035158206104,\n",
       " 0.7766279351246671,\n",
       " 0.7271539298493567,\n",
       " 0.7790779598713432)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlr_test = nn.Sequential(\n",
    "    nn.Linear(20, 532),\n",
    "    nn.ReLU(),\n",
    "    MTLR(532, 29, num_events=2)\n",
    ")\n",
    "mtlr_test = train_mtlr(X_train, y_train, mtlr_test, time_bins, num_epochs=1000, \n",
    "                  lr=.0001, batch_size=128, verbose=True, device=device)\n",
    "\n",
    "validate(mtlr_test, X_test, dff[\"time\"], dff[\"event\"], dff[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch    6/1000]:   0%|          | 4/1000 [00:00<00:32, 30.88it/s, loss = 422.3957]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1351, 20]) torch.Size([1351, 58])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch  1000/1000]: 100%|██████████| 1000/1000 [00:31<00:00, 31.29it/s, loss = 2.3196]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7649268071131609,\n",
       " 0.7703038005325586,\n",
       " 0.7253087458357169,\n",
       " 0.7750497779139225)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlr_test = nn.Sequential(\n",
    "    nn.Linear(20, 532),\n",
    "    nn.ReLU(),\n",
    "    MTLR(532, 29, num_events=2)\n",
    ")\n",
    "mtlr_test = train_mtlr(X_train, y_train, mtlr_test, time_bins, num_epochs=1000, \n",
    "                  lr=.0001, batch_size=128, verbose=True, device=device)\n",
    "\n",
    "validate(mtlr_test, X_test, dff[\"time\"], dff[\"event\"], dff[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch    4/1000]:   0%|          | 2/1000 [00:00<00:52, 19.07it/s, loss = 453.1712]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1351, 20]) torch.Size([1351, 58])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch  1000/1000]: 100%|██████████| 1000/1000 [01:01<00:00, 16.14it/s, loss = 1.6403]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7330934330200654,\n",
       " 0.7645848462841927,\n",
       " 0.7245628203833945,\n",
       " 0.7376474192066166)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlr_test = nn.Sequential(\n",
    "    nn.Linear(20, 532),\n",
    "    nn.ReLU(),\n",
    "    #nn.Dropout(0.4),\n",
    "    nn.Linear(532, 532),\n",
    "    nn.ReLU(),\n",
    "    #nn.Dropout(0.4),\n",
    "    MTLR(532, 29, num_events=2)\n",
    ")\n",
    "mtlr_test = train_mtlr(X_train, y_train, mtlr_test, time_bins, num_epochs=1000, \n",
    "                  lr=.0001, batch_size=128, verbose=True, device=device)\n",
    "\n",
    "validate(mtlr_test, X_test, dff[\"time\"], dff[\"event\"], dff[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch    4/1000]:   0%|          | 2/1000 [00:00<00:50, 19.87it/s, loss = 448.1322]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1351, 20]) torch.Size([1351, 58])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch  1000/1000]: 100%|██████████| 1000/1000 [01:04<00:00, 15.58it/s, loss = 1.8524]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7412453854126634, 0.771536855482934, 0.7329867303787956, 0.7451064481543881)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtlr_test = nn.Sequential(\n",
    "    nn.Linear(20, 532),\n",
    "    nn.ReLU(),\n",
    "    #nn.Dropout(0.4),\n",
    "    nn.Linear(532, 532),\n",
    "    nn.ReLU(),\n",
    "    #nn.Dropout(0.4),\n",
    "    MTLR(532, 29, num_events=2)\n",
    ")\n",
    "mtlr_test = train_mtlr(X_train, y_train, mtlr_test, time_bins, num_epochs=1000, \n",
    "                  lr=.0001, batch_size=128, verbose=True, device=device)\n",
    "\n",
    "validate(mtlr_test, X_test, dff[\"time\"], dff[\"event\"], dff[\"cancer_death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
